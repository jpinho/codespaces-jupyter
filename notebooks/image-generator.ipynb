{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers.git\n",
      "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-2gqos5wp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-2gqos5wp\n",
      "  Resolved https://github.com/huggingface/diffusers.git to commit b811964a7b7f3c4cd50dc25a58789a0fed351e09\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from diffusers==0.16.0.dev0) (1.24.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from diffusers==0.16.0.dev0) (2.28.2)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.10/site-packages (from diffusers==0.16.0.dev0) (9.5.0)\n",
      "Collecting huggingface-hub>=0.13.2\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from diffusers==0.16.0.dev0) (3.10.7)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.3.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.6/769.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-6.4.1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from transformers) (4.64.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from accelerate) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.16.0.dev0) (4.5.0)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->diffusers==0.16.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->diffusers==0.16.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->diffusers==0.16.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests->diffusers==0.16.0.dev0) (1.26.15)\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.16.0.dev0-py3-none-any.whl size=852945 sha256=d8f5fa36bd2ef9d2ac49605586e7ee6866c8b745d2de2895a930eb09edb78ec1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jqod507d/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n",
      "Successfully built diffusers\n",
      "Installing collected packages: tokenizers, zipp, regex, importlib-metadata, huggingface-hub, accelerate, transformers, diffusers\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts accelerate, accelerate-config and accelerate-launch are installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script diffusers-cli is installed in '/usr/local/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed accelerate-0.18.0 diffusers-0.16.0.dev0 huggingface-hub-0.13.4 importlib-metadata-6.4.1 regex-2023.3.23 tokenizers-0.13.3 transformers-4.28.1 zipp-3.15.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data must be str, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mimport\u001b[39;00m environ\n\u001b[1;32m      4\u001b[0m token \u001b[39m=\u001b[39m environ\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mHUGGING_FACE_TOKEN\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m HfFolder\u001b[39m.\u001b[39;49msave_token(token)\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/huggingface_hub/utils/_hf_folder.py:42\u001b[0m, in \u001b[0;36mHfFolder.save_token\u001b[0;34m(cls, token)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mSave token, creating folder as needed.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m        The token to save to the [`HfFolder`]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mpath_token\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 42\u001b[0m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mpath_token\u001b[39m.\u001b[39;49mwrite_text(token)\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/pathlib.py:1149\u001b[0m, in \u001b[0;36mPath.write_text\u001b[0;34m(self, data, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39mOpen the file in text mode, write to it, and close the file.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1149\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mdata must be str, not \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1150\u001b[0m                     data\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1151\u001b[0m encoding \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m   1152\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors, newline\u001b[39m=\u001b[39mnewline) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[0;31mTypeError\u001b[0m: data must be str, not NoneType"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "from os import environ\n",
    "\n",
    "token = environ.get(\"HUGGING_FACE_TOKEN\")\n",
    "HfFolder.save_token(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-2\"\n",
    "\n",
    "# Use the Euler scheduler here instead\n",
    "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16)\n",
    "device = \"cuda\"\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Change prompt for image here!\u001b[39;00m\n\u001b[1;32m      4\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma cartoon black girl with cotton candy hair and a pink dress standing in front of a pink sky with cotton candy clouds\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mwith\u001b[39;00m autocast(device):\n\u001b[1;32m      6\u001b[0m   image \u001b[39m=\u001b[39m pipe(prompt, height\u001b[39m=\u001b[39m\u001b[39m768\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39m768\u001b[39m)\u001b[39m.\u001b[39mimages[\u001b[39m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m image\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import autocast\n",
    "\n",
    "# Change prompt for image here!\n",
    "prompt = \"the incredible hulk running like David Goggins\"\n",
    "with autocast(device):\n",
    "  image = pipe(prompt, height=768, width=768).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
